---
title: "Advanced Inference: 3 - Inference and Prediction"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
#devtools::install_github("rundel/learnrhash")

library(learnr)
library(tidyverse)
library(openintro)
library(grid)
library(png)
#library(emo)

knitr::opts_chunk$set(echo = FALSE,
                      fig.align = "center",
                      fig.height = 3,
                      fig.width = 5,
                      message = FALSE,
                      warning = FALSE)

tutorial_options(exercise.eval = FALSE)

# Hash generation helpers
# Should ideally be loaded from the imstutorials package when it exists
is_server_context <- function(.envir) {
  # We are in the server context if there are the follow:
  # * input - input reactive values
  # * output - shiny output
  # * session - shiny session
  #
  # Check context by examining the class of each of these.
  # If any is missing then it will be a NULL which will fail.
  
  inherits(.envir$input, "reactivevalues") &
    inherits(.envir$output, "shinyoutput") &
    inherits(.envir$session, "ShinySession")
}

check_server_context <- function(.envir) {
  if (!is_server_context(.envir)) {
    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])
    err <- paste0("Function `", calling_func, "`", " must be called from an Rmd chunk where `context = \"server\"`")
    stop(err, call. = FALSE)
  }
}
encoder_logic <- function(strip_output = FALSE) {
  p <- parent.frame()
  check_server_context(p)
  # Make this var available within the local context below
  assign("strip_output", strip_output, envir = p)
  # Evaluate in parent frame to get input, output, and session
  local(
    {
      encoded_txt <- shiny::eventReactive(
        input$hash_generate,
        {
          # shiny::getDefaultReactiveDomain()$userData$tutorial_state
          state <- learnr:::get_tutorial_state()
          shiny::validate(shiny::need(length(state) > 0, "No progress yet."))
          shiny::validate(shiny::need(nchar(input$name) > 0, "No name entered."))
          shiny::validate(shiny::need(nchar(input$studentID) > 0, "Please enter your student ID"))
          user_state <- purrr::map_dfr(state, identity, .id = "label")
          user_state <- dplyr::group_by(user_state, label, type, correct)
          user_state <- dplyr::summarize(
            user_state,
            answer = list(answer),
            timestamp = dplyr::first(timestamp),
            .groups = "drop"
          )
          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)
          user_info <- tibble(
            label = c("student_name", "student_id"),
            type = "identifier",
            answer = as.list(c(input$name, input$studentID)),
            timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z", tz = "UTC")
          )
          learnrhash::encode_obj(bind_rows(user_info, user_state))
        }
      )
      output$hash_output <- shiny::renderText(encoded_txt())
    },
    envir = p
  )
}

hash_encoder_ui <- {
  shiny::div("If you have completed this tutorial and are happy with all of your", "solutions, please enter your identifying information, then click the button below to generate your hash", textInput("name", "What's your name?"), textInput("studentID", "What is your student ID?"), renderText({
    input$caption
  }), )
}
```

## Welcome

In this tutorial, you'll learn more about inference and prediction for regression models. Our main goal is to learn how to quantify uncertainty not just in our model parameters, but also in the predictions that we make with them. To start, let's review the workflow for estimating parameters. 


### Review: estimate parameters

Fit a linear model to the following dataset containing records of flights out of New York City in 2013. In particular, model the relationship between distance and air time. Then print a summary of the model results.

```{r, echo=FALSE}
# Dataset is too big for our purposes, just take 100 samples and select the
# two columns of interest
nycflights <- nycflights %>% 
  select(distance, air_time) %>%
  sample_n(size=40)

head(nycflights)
```

```{r ex1, exercise=TRUE}
model <- lm(data=nycflights, _____)
```

```{r ex1-solution}
model <- lm(data=nycflights, air_time ~ distance)
summary(model)
```

```{r mc1, echo=FALSE}
question("Is there a correlation between flight distance and air time?",
         answer("Yes", correct=TRUE),
         answer("No"),
         answer("Not sure"))
```

```{r, echo=FALSE}
ggplot(data=nycflights, aes(x=distance, y=air_time)) + 
  geom_point() +
  geom_smooth(method="lm", formula=(y~x), se=FALSE, color="blue")
```

$y = 18.655 + 0.1269x + residuals$

```{r mc2, echo=FALSE}
question("How would you interpret the model parameters above?",
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 12.69 minutes"),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 0.1269 minutes.", correct=TRUE),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 18.66 minutes."),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 1.866 minutes."),
         answer("Not sure"))
```


### Review: quantifying (un)certainty

As we would expect, there is a strong correlation ($p=2.0\times10^{-16}$) between flight distance and air time. The average increase of $0.1269$ minutes is a point estimate based on a sample of $n=100$ flights. Given the model output above and any relevant R functions, construct a $95\%$ confidence interval to give an interval estimate of the true $\beta_1$:

```{r ex2, exercise=TRUE}
```

```{r ex2-hint1}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079
```

```{r ex2-hint2}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98
```

```{r ex2-hint3}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98

# To compute the critical t value, use the qt() function:
t_crit <- qt(p=0.05/2, df=98)
```

```{r ex2-solution}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98

# To compute the critical t value, use the qt() function, and remember we are
# computing a two-sided CI:
t_crit <- qt(p=0.05/2, df=98)

# Now compute the full interval:
0.1269 + c(-1,1)*t_crit*0.002079
```

*TODO: check above*

### Predicting future values

Now imagine you're flying direct from NYC to BOS - about 187 miles. Your model can predict how long this flight might take:

$\hat{y} = 18.66 + (0.1269\times187) = 42.39$ minutes

But we know this model is based on our sample of 100 flights, and that the estimate might be different if we had generated the model from a different sample (this is called sample variation). Another way to think about it is this: imagine we knew $\beta_0$ and $\beta_1$ exactly. Then we would know $y$, too, right? 

Well, no - we still don't know $\epsilon$, the `residuals` in the equation $y = \beta_0 + \beta_1x + residuals$. $\epsilon$ is a random variable, and we assume it has a normal distribution with mean 0 and variance $\sigma^2$ - but it is still random, and thus, uncertain. 

So, our flight from NYC to BOS may take *about* 42.39 minutes, plus or minus some error term. We'll need to adapt our tools to quantify the uncertainty we have about this error term - more on that below.


## Simulation Approach

### 

In this simulation, we'll use bootstrapping to take a closer look at sample variation (introduced above). The model you generated for flight distance vs air time, $y = 18.66 + 0.1269x + residuals$, was based on a sample of $n=100$ flights. If you had a slightly different sample, then the model would be different too. 

Recall from Tutorial 5 the lesson on bootstrapping: from our data sample, we generated more data by sampling from the original dataset (under the null hypothesis) with replacement. If we repeat that many times for this example, we can show how the models change with each new sample set.

```{r}
# using infer package, as in tutorial 5
# https://infer.netlify.app/articles/infer#introduction
library(infer)

bSlopes <- nycflights |>
  specify(air_time ~ distance) |>
  generate(reps=1000, type="bootstrap") |>
  calculate(stat="slope")

head(bSlopes)  # display the table of calculated slope values
summarize(bSlopes, se=sd(stat))  # compute the SE
```

Note how the slope SE here (0.00318) is higher than in our original model (0.00307). This is because, in using a bootstrap method, we have resampled the dataset and thus added some uncertainty to the estimates. 

***TODO: talk thru this tutorial more***

#### (From-scratch methods, don't seem to be working - delete from here down)
First, we'll need to write a function that generates our boostrapped samples and their corresponding linear models:
```{r}
boots <- function(data=nycflights, n=1000) {
  # Generate n bootstrapped samples
  bsample <- data %>% sample_n(size=n, replace=TRUE)  # FIXME: not how bootstrap samples work
  
  # Create a model from the bootstrapped samples
  bmodel <- lm(data=bsample, air_time ~ distance)
  
  # Grab the coefficients from the model
  bIntercept <- bmodel$coefficients[["(Intercept)"]]
  bSlope <- bmodel$coefficients[["distance"]]
  
  # Grab residual SE
  bResidSE <- summary(bmodel)$sigma  #sd(bmodel$residuals)
  
  # Grab SE of just the slope parameter
  bSlopeSE <- sqrt(diag(vcov(bmodel)))[["distance"]]
  
  return(list(bIntercept, bSlope, bResidSE, bSlopeSE))
}
```

Now let's write a function to generate predicted y values from those models:

```{r}
generate_y <- function(coeffs) {
  x <- nycflights$distance
  y <- nycflights$air_time
  
  # Create an empty dataframe to hold the x, y, and y_pred values
  pred_y <- data.frame()
  
  # Compute y_pred for each x, given the coefficients
  for(k in 1:ncol(coeffs)) {
    y_pred <- coeffs[1,k] + coeffs[2,k]*x
    line <- colnames(coeffs)[k]
    
    row <- data.frame(x=x, y=y, y_pred=y_pred, line=line)
    pred_y <- rbind(pred_y, row)
  }
  
  return(pred_y)
}
```

```{r}
K <- 7   # number of bootstrap simulations to run - and the number of models
x <- nycflights$distance
coeffs <- matrix(nrow=2, ncol=K, byrow=TRUE)
rownames(coeffs) <- c("Intercept", "Slope") 
colnames(coeffs) <- paste0("B-line", seq_len(ncol(coeffs)))

for(k in 1:K) {
  sim <- boots(n=250)
  coeffs[1,k] <- sim[[1]]
  coeffs[2,k] <- sim[[2]]
}

# Create a dataframe of model coefficients 
coeffs <- data.frame(coeffs)

# Generate predicted y values
predicted <- generate_y(coeffs)

# Plot
ggplot(data=predicted, aes(x=x, y=y)) +
  geom_point(color="black", alpha=0.6) +
  geom_line(data=predicted, aes(x=x, y=y_pred, color=line))
```

Note how each model is slightly different, and none fit the data exactly: we still have some error.


## Extrapolation

```{r, include=FALSE}
# Simulate a dataset that makes extrapolation outside of a given range tricky
x <- c(5,6,7,11,12,13,14)
y <- c(8,12,11,21,23,26,25)
observed <- data.frame(cbind(x,y))

x <- c(3,3.5,4.5,15:20)
y <- c(0,4,5,26,23,25,22,20,19)
unobserved <- data.frame(cbind(x,y))
```

In this section, we'll look at the difference between _interpolation_ and _extrapolation_ in inference and prediction, and how to choose the correct approach. Below, you're given a dataframe called `observed` that contains all of the data you observe. How might you try to model these data?

```{r, echo=FALSE}
ggplot(data=observed, aes(x=x,y=y)) +
  geom_point() +
  xlim(c(0,20))
```

Let's try fitting a linear model, in particular to fill the gap in the neighborhood of x=10. We call this _interpolation_: making predictions based on observed data on new values that are still within the observed range.

```{r}
ggplot(data=observed, aes(x=x,y=y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  xlim(c(0,20))
```

```{r, include=FALSE}
observed$observed <- rep(TRUE, nrow(observed))
unobserved$observed <- rep(FALSE, nrow(unobserved))
fullData <- rbind(observed, unobserved)
```

You're fairly confident that your model can predict the values around x=10, but what about x=0 or x=20? Since these values lie outside the observed range of your data, such a prediction task is called _extrapolation_. Say you make your extrapolations using the model based on observed data, and then new data comes in:

```{r}
ggplot(data=fullData, aes(x=x,y=y,color=observed)) +
  geom_point() +
  geom_smooth(data=observed, method='lm', formula=y~x, se=FALSE)
```

As you can see, the model based on observed data is not likely to extrapolate well if you want to predict values far outside the observed range. 


## Your turn!

First, we load the following dataset, which contains many observations of mammal size in different stages of the animals' lives. Note that the .csv file is tab-delimited. 

```{r}
mammals <- read.csv("sizeHistory.csv", sep="\t")
head(mammals)
```

We will need to log-transform both the response and the independent variables in this dataset. If we want to model adult mass (`mass.g.`) vs newborn mass (`newborn.g.`), perform the log transformations below:

```{r ex3, exercise=TRUE}
mammals$logAdultMass <- _____

mammals$logNewbornMass <- _____
```

```{r ex3-solution}
mammals$logAdultMass <- log(mammals$mass.g.)
mammals$logNewbornMass <- log(mammals$newborn.g.)
```

Create a scatterplot of the log-adult mass (`logAdultMass`) and newborn mass (`logNewbornMass`). 
```{r ex4, exercise=TRUE}
ggplot(data=____, aes(x=_____, y=_____)) +
  _____
```

```{r ex4-solution}
ggplot(data=mammals, aes(x=logNewbornMass, y=logAdultMass)) +
  geom_point()
```

Now, let's try to predict the log-adult mass of mammals with the following log-newborn masses:

- 0.1 (remember that this is a log scale - this newborn is very small!)
- 12.0 (newborn mass around $e^12$ grams, near the maximum observed)
- 20 (newborn mass around $e^20$ grams, well beyond the maximum observed)

First, create a linear regression model for the data
```{r ex5, exercise=TRUE}
```
