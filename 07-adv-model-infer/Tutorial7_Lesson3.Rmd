---
title: "Advanced Inference: 3 - Inference and Prediction"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
#devtools::install_github("rundel/learnrhash")

library(learnr)
library(tidyverse)
library(openintro)
library(grid)
library(png)
#library(emo)

knitr::opts_chunk$set(echo = FALSE,
                      fig.align = "center",
                      fig.height = 3,
                      fig.width = 5,
                      message = FALSE,
                      warning = FALSE)

tutorial_options(exercise.eval = FALSE)

# Hash generation helpers
# Should ideally be loaded from the imstutorials package when it exists
is_server_context <- function(.envir) {
  # We are in the server context if there are the follow:
  # * input - input reactive values
  # * output - shiny output
  # * session - shiny session
  #
  # Check context by examining the class of each of these.
  # If any is missing then it will be a NULL which will fail.
  
  inherits(.envir$input, "reactivevalues") &
    inherits(.envir$output, "shinyoutput") &
    inherits(.envir$session, "ShinySession")
}

check_server_context <- function(.envir) {
  if (!is_server_context(.envir)) {
    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])
    err <- paste0("Function `", calling_func, "`", " must be called from an Rmd chunk where `context = \"server\"`")
    stop(err, call. = FALSE)
  }
}
encoder_logic <- function(strip_output = FALSE) {
  p <- parent.frame()
  check_server_context(p)
  # Make this var available within the local context below
  assign("strip_output", strip_output, envir = p)
  # Evaluate in parent frame to get input, output, and session
  local(
    {
      encoded_txt <- shiny::eventReactive(
        input$hash_generate,
        {
          # shiny::getDefaultReactiveDomain()$userData$tutorial_state
          state <- learnr:::get_tutorial_state()
          shiny::validate(shiny::need(length(state) > 0, "No progress yet."))
          shiny::validate(shiny::need(nchar(input$name) > 0, "No name entered."))
          shiny::validate(shiny::need(nchar(input$studentID) > 0, "Please enter your student ID"))
          user_state <- purrr::map_dfr(state, identity, .id = "label")
          user_state <- dplyr::group_by(user_state, label, type, correct)
          user_state <- dplyr::summarize(
            user_state,
            answer = list(answer),
            timestamp = dplyr::first(timestamp),
            .groups = "drop"
          )
          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)
          user_info <- tibble(
            label = c("student_name", "student_id"),
            type = "identifier",
            answer = as.list(c(input$name, input$studentID)),
            timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z", tz = "UTC")
          )
          learnrhash::encode_obj(bind_rows(user_info, user_state))
        }
      )
      output$hash_output <- shiny::renderText(encoded_txt())
    },
    envir = p
  )
}

hash_encoder_ui <- {
  shiny::div("If you have completed this tutorial and are happy with all of your", "solutions, please enter your identifying information, then click the button below to generate your hash", textInput("name", "What's your name?"), textInput("studentID", "What is your student ID?"), renderText({
    input$caption
  }), )
}
```

## Welcome

In this tutorial, you'll learn more about inference and prediction for regression models. Our main goal is to learn how to quantify uncertainty not just in our model parameters, but also in the predictions that we make with them. To start, let's review the workflow for estimating parameters. 


### Review: estimate parameters

Fit a linear model to the following dataset containing records of flights out of New York City in 2013. In particular, model the relationship between distance and air time. Then print a summary of the model results.

```{r, echo=FALSE}
# Dataset is too big for our purposes, just take 100 samples and select the
# two columns of interest
nycflights <- nycflights %>% 
  select(distance, air_time) %>%
  sample_n(size=100)

head(nycflights)
```

```{r ex1, exercise=TRUE}
model <- lm(data=nycflights, _____)
```

```{r ex1-solution}
model <- lm(data=nycflights, air_time ~ distance)
summary(model)
```

```{r mc1, echo=FALSE}
question("Is there a correlation between flight distance and air time?",
         answer("Yes", correct=TRUE),
         answer("No"),
         answer("Not sure"))
```

```{r, echo=FALSE}
ggplot(data=nycflights, aes(x=distance, y=air_time)) + 
  geom_point() +
  geom_smooth(method="lm", formula=(y~x), se=FALSE, color="blue")
```

$y = 18.655 + 0.1269x + residuals$

```{r mc2, echo=FALSE}
question("How would you interpret the model parameters above?",
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 12.69 minutes"),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 0.1269 minutes.", correct=TRUE),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 18.66 minutes."),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 1.866 minutes.")
         answer("Not sure"))
```


### Review: quantifying (un)certainty

As we would expect, there is a strong correlation ($p=2.0\times10^{-16}$) between flight distance and air time. The average increase of $0.1269$ minutes is a point estimate based on a sample of $n=100$ flights. Given the model output above and any relevant R functions, construct a $95\%$ confidence interval to give an interval estimate of the true $\beta_1$:

```{r ex2, exercise=TRUE}
```

```{r ex2-hint}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079
```

```{r ex2-hint}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98
```

```{r ex2-hint}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98

# To compute the critical t value, use the qt() function:
t_crit <- qt(p=0.05/2, df=98)
```

```{r ex2-solution}
# You have the point estimate, b1=0.1269, and the model summary gives you the
# standard error for this estimate: SE = 0.002079

# Now for the degrees of freedom: you have n=100 samples, so df = n-2 = 98

# To compute the critical t value, use the qt() function, and remember we are
# computing a two-sided CI:
t_crit <- qt(p=0.05/2, df=98)

# Now compute the full interval:
0.1269 + c(-1,1)*t_crit*0.002079
```

*TODO: check above*

### Predicting future values

Now imagine you're flying direct from NYC to BOS - about 187 miles. Your model can predict how long this flight might take:

$\hat{y} = 18.66 + (0.1269\times187) = 42.39$ minutes

But we know this model is based on our sample of 100 flights, and that the estimate might be different if we had generated the model from a different sample (this is called sample variation). Another way to think about it is this: imagine we knew $\beta_0$ and $\beta_1$ exactly. Then we would know $y$, too, right? 

Well, no - we still don't know $\epsilon$, the `residuals` in the equation $y = \beta_0 + \beta_1x + residuals$. $\epsilon$ is a random variable, and we assume it has a normal distribution with mean 0 and variance $\sigma^2$ - but it is still random, and thus, uncertain. 

So, our flight from NYC to BOS may take *about* 42.39 minutes, plus or minus some error term. We'll need to adapt our tools to quantify the uncertainty we have about this error term - more on that below.


## Simulation

### 

In this simulation, we'll use bootstrapping to take a closer look at sample variation (introduced above). The model you generated for flight distance vs air time, $y = 18.66 + 0.1269x + residuals$, was based on a sample of $n=100$ flights. If you had a slightly different sample, then the model would be different too. 

Recall from Tutorial 5 the lesson on bootstrapping: from our data sample, we generated more data by sampling from the original dataset (under the null hypothesis) with replacement. If we repeat that many times for this example, we can show how the models change with each new sample set.

First, we'll need to write a function that generates our boostrapped samples and their corresponding linear models:
```{r}
boots <- function(data=nycflights, n=15000) {
  # Generate n bootstrapped samples
  bsample <- data %>% sample_n(size=n, replace=TRUE)
  
  # Create a model from the bootstrapped samples
  bmodel <- lm(data=bsample, air_time ~ distance)
  
  # Grab the coefficients from the model
  bIntercept <- bmodel$coefficients[["(Intercept)"]]
  bSlope <- bmodel$coefficients[["distance"]]
  
  # TODO: compute SE of slope as well (formula in stat_more_inf)
  # TODO: sample from error distribution = epsilon dist, Gaussian w sigma^2 hat
  return(list(bIntercept, bSlope, ypred))
}
```

Now let's write a function to generate predicted y values from those models:

```{r}
generate_y <- function(coeffs) {
  x <- nycflights$distance
  y <- nycflights$air_time
  
  pred_y <- data.frame()
  
  for(k in 1:ncol(coeffs)) {
    y_pred <- coeffs[1,k] + coeffs[2,k]*x
    line <- colnames(coeffs)[k]
    
    row <- data.frame(x=x, y=y, y_pred=y_pred, line=line)
    pred_y <- rbind(pred_y, row)
  }
  
  return(pred_y)
}
```

```{r}
K <- 3   # number of bootstrap simulations to run - and the number of models
x <- nycflights$distance
coeffs <- matrix(nrow=2, ncol=K, byrow=TRUE)
rownames(coeffs) <- c("Intercept", "Slope") 
colnames(coeffs) <- paste0("B-line", seq_len(ncol(coeffs)))

for(k in 1:K) {
  sim <- boots(n=250)
  coeffs[1,k] <- sim[[1]]
  coeffs[2,k] <- sim[[2]]
}

# Create a dataframe of model coefficients 
coeffs <- data.frame(coeffs)

# Generate predicted y values
predicted <- generate_y(coeffs)

# Plot
ggplot(data=predicted, aes(x=x, y=y)) +
  geom_point(color="black", alpha=0.6) +
  geom_line(data=predicted, aes(x=x, y=y_pred, color=line))

# TODO: plotted lines don't display well, maybe original dataset is too large - try n=40?
```
