---
title: "Advanced Inference: 3 - Inference and Prediction"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
#devtools::install_github("rundel/learnrhash")

library(learnr)
library(tidyverse)
library(openintro)
library(grid)
library(png)
#library(emo)

knitr::opts_chunk$set(echo = FALSE,
                      fig.align = "center",
                      fig.height = 3,
                      fig.width = 5,
                      message = FALSE,
                      warning = FALSE)

tutorial_options(exercise.eval = FALSE)

# Hash generation helpers
# Should ideally be loaded from the imstutorials package when it exists
is_server_context <- function(.envir) {
  # We are in the server context if there are the follow:
  # * input - input reactive values
  # * output - shiny output
  # * session - shiny session
  #
  # Check context by examining the class of each of these.
  # If any is missing then it will be a NULL which will fail.
  
  inherits(.envir$input, "reactivevalues") &
    inherits(.envir$output, "shinyoutput") &
    inherits(.envir$session, "ShinySession")
}

check_server_context <- function(.envir) {
  if (!is_server_context(.envir)) {
    calling_func <- deparse(sys.calls()[[sys.nframe() - 1]])
    err <- paste0("Function `", calling_func, "`", " must be called from an Rmd chunk where `context = \"server\"`")
    stop(err, call. = FALSE)
  }
}
encoder_logic <- function(strip_output = FALSE) {
  p <- parent.frame()
  check_server_context(p)
  # Make this var available within the local context below
  assign("strip_output", strip_output, envir = p)
  # Evaluate in parent frame to get input, output, and session
  local(
    {
      encoded_txt <- shiny::eventReactive(
        input$hash_generate,
        {
          # shiny::getDefaultReactiveDomain()$userData$tutorial_state
          state <- learnr:::get_tutorial_state()
          shiny::validate(shiny::need(length(state) > 0, "No progress yet."))
          shiny::validate(shiny::need(nchar(input$name) > 0, "No name entered."))
          shiny::validate(shiny::need(nchar(input$studentID) > 0, "Please enter your student ID"))
          user_state <- purrr::map_dfr(state, identity, .id = "label")
          user_state <- dplyr::group_by(user_state, label, type, correct)
          user_state <- dplyr::summarize(
            user_state,
            answer = list(answer),
            timestamp = dplyr::first(timestamp),
            .groups = "drop"
          )
          user_state <- dplyr::relocate(user_state, correct, .before = timestamp)
          user_info <- tibble(
            label = c("student_name", "student_id"),
            type = "identifier",
            answer = as.list(c(input$name, input$studentID)),
            timestamp = format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z", tz = "UTC")
          )
          learnrhash::encode_obj(bind_rows(user_info, user_state))
        }
      )
      output$hash_output <- shiny::renderText(encoded_txt())
    },
    envir = p
  )
}

hash_encoder_ui <- {
  shiny::div("If you have completed this tutorial and are happy with all of your", "solutions, please enter your identifying information, then click the button below to generate your hash", textInput("name", "What's your name?"), textInput("studentID", "What is your student ID?"), renderText({
    input$caption
  }), )
}
```

## Welcome

In this tutorial, you'll learn more about inference and prediction for regression models. Our main goal is to learn how to quantify uncertainty not just in our model parameters, but also in the predictions that we make with them. To start, let's review the workflow for estimating parameters. 


### Review: estimate parameters

Fit a linear model to the following dataset containing records of flights out of New York City in 2013. In particular, model the relationship between distance and air time. Then print a summary of the model results.

```{r, echo=FALSE}
set.seed(42)

# Dataset is too big for our purposes, just take 40 samples and select the
# two columns of interest
nycflights <- nycflights %>% 
  select(distance, air_time) %>%
  sample_n(size=40) 

# Add some extra noise
nycflights$air_time <- nycflights$air_time + rnorm(n=nrow(nycflights), sd=5)
head(nycflights)

# Store model object, can't knit otherwise
model <- lm(data=nycflights, air_time ~ distance)
```

```{r ex1, exercise=TRUE}
model <- lm(data=nycflights, ____)
```

```{r ex1-solution}
model <- lm(data=nycflights, air_time ~ distance)
summary(model)
```

###

```{r, echo=FALSE}
ggplot(data=nycflights, aes(x=distance, y=air_time)) + 
  geom_point() +
  geom_smooth(method="lm", formula=(y~x), se=FALSE, color="blue")
```

```{r mc1, echo=FALSE}
question("Is there a correlation between flight distance and air time?",
         answer("Yes", correct=TRUE),
         answer("No"),
         answer("Not sure"))
```

###

Here is the model you should've gotten from your summary:

$y = 18.36 + 0.126x + residuals$

```{r mc2, echo=FALSE}
question("How would you interpret the model parameters above?",
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 12.6 minutes"),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 0.126 minutes.", correct=TRUE),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 18.36 minutes."),
         answer("For each one-mile increase in flight distance, the model predicts that the corresponding air time increases by 1.836 minutes."),
         answer("Not sure"))
```


### Review: quantifying (un)certainty

As we would expect, there is a strong correlation ($p=2.2\times10^{-16}$) between flight distance and air time. The average increase of $0.126$ minutes is a point estimate based on a sample of $n=40$ flights. Given the model output above and any relevant R functions, construct a $95\%$ confidence interval to give an interval estimate of the true $\beta_1$:

```{r ex2, exercise=TRUE}
```

```{r ex2-hint1}
# You have the point estimate, b1=0.126, and the model summary gives you the
# standard error for this estimate: SE = 0.002978
```

```{r ex2-hint2}
# You have the point estimate, b1=0.126, and the model summary gives you the
# standard error for this estimate: SE = 0.002978

# Now for the degrees of freedom: you have n=40 samples, so df = n-2 = 38
```

```{r ex2-hint3}
# You have the point estimate, b1=0.126, and the model summary gives you the
# standard error for this estimate: SE = 0.002978

# Now for the degrees of freedom: you have n=40 samples, so df = n-2 = 38

# To compute the critical t value, use the qt() function:
t_crit <- qt(p=0.05/2, df=38)
```

```{r ex2-solution}
# You have the point estimate, b1=0.126, and the model summary gives you the
# standard error for this estimate: SE = 0.002978

# Now for the degrees of freedom: you have n=40 samples, so df = n-2 = 38

# To compute the critical t value, use the qt() function, and remember we are
# computing a two-sided CI:
t_crit <- qt(p=0.05/2, df=38)

# Now compute the full interval:
0.126 + c(-1,1)*t_crit*0.002978
```

*TODO: check above*


## Predicting future values

Now imagine you're flying direct from NYC to BOS - about 187 miles. Your model can predict how long this flight might take:

$\hat{y} = 18.36 + (0.126\times187) = 41.92$ minutes

But we know this model is based on our sample of 40 flights, and that the estimate might be different if we had generated the model from a different sample (this is called sample variation). Another way to think about it is this: imagine we knew $\beta_0$ and $\beta_1$ exactly. Then we would know $y$, too, right? 

###

### Model-based approach

Well, no - we still don't know $\epsilon$, the `residuals` in the equation $y = \beta_0 + \beta_1x + residuals$. $\epsilon$ is a random variable, and we assume it has a normal distribution with mean 0 and variance $\sigma^2$. In the process of performing linear regression we estimate $\hat\sigma^2$, but there is still uncertainty inherent to the model.

For example, there are two rows in the dataset corresponding to a flight of distance 529 miles:

```{r}
subset(nycflights, distance == 529)
```

Note how different the response values $y$ are! To visualize this, let's plot our regression line and the two `distance=529` points below: 

```{r, echo=FALSE}
x <- seq(100,1000)
example <- data.frame(x)
example$yhat <- 18.36 + 0.126*x

subset <- subset(nycflights, distance == 529)  

ggplot() +
  geom_line(data=example, aes(x=x,y=yhat), color='blue') +
  geom_point(data=subset, aes(x=distance, y=air_time)) +
  xlim(c(100,1000))
```

The uncertainty here, shown by the marked difference between our predicted values (blue line) and the observed values (points), is determined by the `residuals` term in our model. In the next section, we'll use different approaches to analyze this uncertainty. So, we'll need to adapt our tools to quantify the uncertainty we have about this error term - more on that below.


## Simulation

### 

In this simulation, we'll use bootstrapping to take a closer look at sample variation (introduced above). The model you generated for flight distance vs air time, $y = 18.66 + 0.1269x + residuals$, was based on a sample of $n=40$ flights. If you had a slightly different sample, then the model would be different too. 

Recall from Tutorial 5 the lesson on bootstrapping: from our data sample, we generated more data by sampling from the original dataset (under the null hypothesis) with replacement. If we repeat that many times for this example, we can show how the models change with each new sample set.


## Bootstrapping regression estimates

First, let's fit a sequence of 100 bootstrap estimates for our intercept and slope parameters:

```{r, echo=TRUE}
# using infer package, as in tutorial 5
# https://infer.netlify.app/articles/infer#introduction
library(infer)

# Generate fitted models from 100 bootstrapped estimates:
boots <- nycflights |>
  specify(air_time ~ distance) |>
  generate(reps=100, type="bootstrap") |>
  fit()

head(boots)  # display the table of estimated parameters

# Grab the parameters
bIntercepts <- subset(data.frame(boots), term=="intercept")["estimate"]
bSlopes <- subset(data.frame(boots), term=="distance")["estimate"]
```

###

Now let's compute the predicted values for each bootstrapped model, so we can plot them and see how they differ:

```{r, echo=TRUE}
# Create a matrix to hold the predicted values
bPredictions <- matrix(nrow=nrow(bIntercepts)*nrow(nycflights), ncol=5)
colnames(bPredictions) <- c("distance", "yhat", "y", "residuals", "bootstrapLine")
bPredictions <- data.frame(bPredictions)

bPredictions$distance <- rep(nycflights$distance, nrow(bIntercepts)/nrow(nycflights))
bPredictions$y <- rep(nycflights$air_time, nrow(bIntercepts)/nrow(nycflights))
bPredictions$yhat <- bIntercepts$estimate + (bPredictions$distance * bSlopes$estimate)
bPredictions$residuals <- bPredictions$yhat - bPredictions$y
names <- seq(1:nrow(bIntercepts))
bPredictions$bootstrapLine <- rep(names, nrow(nycflights))

head(bPredictions)
```

Plot the boostrapped models overlaid with a scatterplot of the original data:

```{r, echo=TRUE}
ggplot() +
  geom_line(data=bPredictions, aes(x=distance, y=yhat, color=factor(bootstrapLine)), alpha=0.6) +
  geom_point(data=nycflights, aes(x=distance, y=air_time)) +
  theme(legend.position = "none") 
```

###

Now let's look at the boostrap models' residual SE, and the SE of each boostrapped parameter:

```{r, echo=TRUE}
# Compute the SE for each parameter
se_bInt <- sd(bIntercepts$estimate)
se_bSlopes <- sd(bSlopes$estimate)

# Compute the residual SE
se_bResid <- sd(bPredictions$residuals)

# Original model SE values:
se_mInt <- summary(model)$coefficients[,2][[1]]
se_mSlope <- summary(model)$coefficients[,2][[2]]
se_mResid <- sd(summary(model)$residuals)

# Create a table of values
se_tab <- matrix(c(se_mInt, se_bInt, se_mSlope, se_bSlopes, se_mResid, se_bResid), 
                 ncol=2, byrow=TRUE)
colnames(se_tab) <- c("Original model", "Bootstraps")
rownames(se_tab) <- c("Intercept SE", "Slope SE", "Residual SE")
se_tab <- as.table(se_tab)
print(se_tab)
```

###

Note how the bootstrap SE values are larger than the original model's. This extra uncertainty comes from our bootstrap resampling procedure. To be more concrete, we can examine the formula for the residual SE: for a chosen predictor value $x^*$, our prediction is given by $\hat{y}^* = \beta_0 + \beta_1x^*$, and

$$SE = \sqrt{s_e^2 +\frac{s_e^2}{n} + (SE_{\beta_1})^2 \times (x^*-\bar{x})^2}$$
Let's look at each term in sequence:

- $s_e^2$, the _variance of the residuals_, represents the uncertainty associated with the residuals
- $\frac{s_e^2}{n}$ represents the average contribution to the variance of the residuals of each data pair $(x^*, \hat{y}^*)$
- $(SE_{\beta_1})^2 \times (x^*-\bar{x})^2$: note that this term increases as the distance between $x^*$ and $\bar{x}$ increases, which means that our uncertainty increases as we move away from predicting values near the mean of $x$


## Extrapolation

```{r, include=FALSE}
# Simulate a dataset that makes extrapolation outside of a given range tricky
x <- c(5,6,7,11,12,13,14)
y <- c(8,12,11,21,23,26,25)
observed <- data.frame(cbind(x,y))

x <- c(3,3.5,4.5,15:20)
y <- c(0,4,5,26,23,25,22,20,19)
unobserved <- data.frame(cbind(x,y))
```

In this section, we'll look at the difference between _interpolation_ and _extrapolation_ in inference and prediction, and how to choose the correct approach. Below, you're given a dataframe called `observed` that contains all of the data you observe. How might you try to model these data?

```{r, echo=FALSE}
ggplot(data=observed, aes(x=x,y=y)) +
  geom_point() +
  xlim(c(0,20))
```

Let's try fitting a linear model, in particular to fill the gap in the neighborhood of x=10. We call this _interpolation_: making predictions based on observed data on new values that are still within the observed range.

```{r}
ggplot(data=observed, aes(x=x,y=y)) +
  geom_point() +
  geom_smooth(method='lm', se=FALSE) +
  xlim(c(0,20))
```

```{r, include=FALSE}
observed$observed <- rep(TRUE, nrow(observed))
unobserved$observed <- rep(FALSE, nrow(unobserved))
fullData <- rbind(observed, unobserved)
```

You're fairly confident that your model can predict the values around x=10, but what about x=0 or x=20? Since these values lie outside the observed range of your data, such a prediction task is called _extrapolation_. Say you make your extrapolations using the model based on observed data, and then new data comes in:

```{r}
ggplot(data=fullData, aes(x=x,y=y,color=observed)) +
  geom_point() +
  geom_smooth(data=observed, method='lm', formula=y~x, se=FALSE)
```

As you can see, the model based on observed data is not likely to extrapolate well if you want to predict values far outside the observed range. 


## Your turn!

First, we load the following dataset, which contains many observations of mammal size in different stages of the animals' lives. Note that the .csv file is tab-delimited. 

```{r}
mammals <- read.csv("sizeHistory.csv", sep="\t")
head(mammals)
```

We will need to log-transform both the response and the independent variables in this dataset. If we want to model adult mass (`mass.g.`) vs newborn mass (`newborn.g.`), perform the log transformations below:

```{r ex3, exercise=TRUE}
mammals$logAdultMass <- _____

mammals$logNewbornMass <- _____
```

```{r ex3-solution}
mammals$logAdultMass <- log(mammals$mass.g.)
mammals$logNewbornMass <- log(mammals$newborn.g.)
```

Create a scatterplot of the log-adult mass (`logAdultMass`) and newborn mass (`logNewbornMass`). 
```{r ex4, exercise=TRUE}
ggplot(data=____, aes(x=_____, y=_____)) +
  _____
```

```{r ex4-solution}
ggplot(data=mammals, aes(x=logNewbornMass, y=logAdultMass)) +
  geom_point()
```

Now, let's try to predict the log-adult mass of mammals with the following log-newborn masses:

- 0.1 (remember that this is a log scale - this newborn is very small!)
- 12.0 (newborn mass around $e^12$ grams, near the maximum observed)
- 20 (newborn mass around $e^20$ grams, well beyond the maximum observed)

First, create a linear regression model for the data
```{r ex5, exercise=TRUE}
```
